# ADR-0001: AI School 仿真平台整体架构

**Status**: Proposed
**Date**: 2026-02-16
**Deciders**: Product & Architecture Team

## Context

AI School 是一个基于 LLM 的学校仿真平台，产品愿景分为两个阶段：

- **Phase 1**：AI School 仿真平台（研究工具）— 通过模拟学生的校园生活，研究学生身心发展与职业匹配规律
- **Phase 2**：学生陪伴机器人（面向用户的产品）— 将研究成果转化为真实学生的陪伴工具

基于 34 篇论文的系统性研究（见 `docs/research/generative-agents-deep-synthesis.md`），我们需要设计一个能支撑以下核心需求的系统架构：

1. 每个学生是一个独立的 LLM Agent，具备差异化人格和目标
2. Agent 在结构化的学校环境中自主活动、社交、学习
3. 人格随经历缓慢演变，记忆分层存储
4. 支持用户干预和研究分析
5. 涌现行为可观察、可追踪、可复现

### 核心研究依据

- **Generative Agents 三公理**：行为 = f(记忆, 情境, 目标)；社会行为是涌现属性；记忆是认知基础设施
- **Concordia Game Master 机制**：智能体用自然语言描述意图 → GM 翻译为环境变化
- **NetworkGames**：网络拓扑 × 人格分布共同决定宏观行为（涌现不可从双人交互预测）
- **LIFELONG-SOTOPIA**：所有模型的长期一致性会衰减，记忆改善有帮助但不充分

## Decision Drivers

- **研究价值优先**：架构需支撑对学生身心发展规律的科学研究
- **涌现行为支持**：系统需允许 Agent 群体产生非预编程的社会行为
- **可观测性**：仿真过程及结果需要可追踪、可回放、可对比
- **渐进式构建**：按优先级分阶段交付，每阶段有独立可运行的最小回路
- **长期演化可靠性**：应对长期交互中行为一致性衰减的已知挑战

## Decision

采用 **6 大模块、18 子模块** 的分层架构，Phase 1 包含 5 个核心模块，Phase 2 包含 1 个产品模块。

### 模块总览

```
AI School
├── M1. 学生 Agent 系统
│   ├── M1.1 人格初始化引擎        ← MBTI 4 维连续分数驱动行为差异
│   ├── M1.2 职业志向模型          ← 理想职业影响学习偏好与社交选择
│   └── M1.3 认知与行为框架        ← 感知-思考-行动循环，人格调制决策
│
├── M2. 学校世界系统
│   ├── M2.1 课程与学习活动        ← 模拟学科学习，产生学业反馈
│   ├── M2.2 社交与校园活动        ← 同伴关系、社团、竞赛等社会互动
│   └── M2.3 环境与时间系统        ← 时间推进、学期节奏、校园空间
│
├── M3. 演化引擎
│   ├── M3.1 自主演化循环          ← Agent 群体日常自主行为与涌现
│   ├── M3.2 用户干预机制          ← 全局/个体、直接/间接干预
│   └── M3.3 事件与冲突生成        ← 自动生成推动发展的关键事件
│
├── M4. 记忆与成长系统
│   ├── M4.1 多层记忆架构          ← 感知→短期→长期→语义分层存储
│   ├── M4.2 身心发展追踪          ← 心理状态、社交能力、学业能力动态记录
│   └── M4.3 人格动态演变          ← 人格特质随经历缓慢演变
│
├── M5. 研究与分析平台
│   ├── M5.1 发展轨迹可视化        ← 身心发展时间线、关键转折点
│   ├── M5.2 职业匹配分析          ← 学生与职业匹配度评估
│   └── M5.3 实验对照与数据导出    ← 多次仿真对比、参数调整、结果导出
│
└── M6. 学生陪伴机器人（Phase 2）
    ├── M6.1 真实学生画像建模
    ├── M6.2 身心健康陪伴
    └── M6.3 职业发展引导
```

### 模块依赖关系

```
M1 (Agent) ──→ M3 (演化引擎) ──→ M5 (研究分析)
    ↓                ↑                    ↓
M2 (世界) ──────────┘               M6 (陪伴机器人)
    ↓                                    ↑
M4 (记忆/成长) ─────────────────────────┘
```

### 建议开发优先级

| 优先级 | 模块 | 理由 |
|--------|------|------|
| P0 | M1.1 人格初始化 + M1.3 认知框架 | 一切的基础，研究基础最充分 |
| P0 | M4.1 多层记忆架构 | 长期演化的核心基础设施 |
| P1 | M2.1 课程系统 + M2.2 社交系统 | 提供 Agent 活动的最小环境 |
| P1 | M3.1 自主演化循环 | 最小可运行的仿真回路 |
| P2 | M3.2 用户干预 + M3.3 事件生成 | 丰富仿真的可控性与戏剧性 |
| P2 | M4.2 身心追踪 + M4.3 人格演变 | 研究价值的核心产出 |
| P3 | M5 研究分析平台 | 数据足够后再建分析能力 |
| P4 | M6 陪伴机器人 | Phase 1 研究验证后启动 |

## Consequences

### Positive

- 6 模块分层清晰，各模块可独立展开 PRD 和迭代开发
- 依赖关系明确，P0→P1→P2 的路径保证每阶段有可运行的最小回路
- 架构与 34 篇论文的研究结论充分对齐（Generative Agents、Concordia、NetworkGames 等）
- Phase 2 (M6) 自然继承 Phase 1 的研究成果

### Negative

- 模块间跨模块交互复杂（特别是 M1↔M3↔M4 的人格演化闭环），需要精心设计接口
- 18 个子模块的协调开发需要严格的接口契约管理
- 部分关键技术决策（LLM 选型、记忆数据库、仿真规模等）尚待各模块 PRD 展开时决定

### Risks

- **长期一致性衰减**：LIFELONG-SOTOPIA 证明所有模型在长期交互中表现下降，记忆架构改善有帮助但不充分
- **涌现不可预测性**：大规模仿真的结果难以先验推断（NetworkGames 的发现）
- **Prompt vs 训练的深度**：Social Alignment 研究警示 Prompt 方法可能只改变表层语言风格而非深层决策行为

## 待决技术决策点

| 编号 | 决策问题 | 影响范围 |
|------|---------|---------|
| D1 | LLM 选型：API 调用 vs 本地部署 vs 混合 | 全局成本与性能 |
| D2 | 人格框架：MBTI 4 维连续分 vs MBTI+Big Five 混合 | M1, M4.3 |
| D3 | 记忆架构：向量数据库选型与分层策略 | M4 |
| D4 | 仿真规模：初始 Agent 数量与并发策略 | M2, M3 |
| D5 | 时间粒度：仿真时间与现实时间的映射比 | M2.3, M3.1 |
| D6 | 干预边界：用户可干预的范围与深度 | M3.2 |
| D7 | 前端形态：Web 可视化 vs 纯数据分析 vs 游戏化界面 | M5, 用户体验 |

## Related Decisions

- [ADR-0002](0002-personality-evolution-mechanism.md): 人格演化跨模块闭环机制
- [ADR-0003](0003-world-system-llm-interaction.md): 学校世界系统与 LLM 交互架构
- [ADR-0004](0004-narrative-data-dual-view.md): 叙事-数据双视图对照设计

## References

- [需求框架文档](../prd/requirements-framework.md)
- [Generative Agents 研究深度综合提炼](../research/generative-agents-deep-synthesis.md)
- Generative Agents (Park et al., UIST 2023) — 奠基架构
- Concordia (Google DeepMind, 2023) — Game Master 机制
- NetworkGames (2025) — 网络拓扑 × 人格涌现
- LIFELONG-SOTOPIA (2025) — 长期一致性评估
